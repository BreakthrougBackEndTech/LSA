{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human machine interface for Lab ABC computer ...</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A survey of user opinion of computer system r...</td>\n",
       "      <td>c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The EPS user interface management system</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>System and human system engineering testing o...</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relation of user-perceived response time to e...</td>\n",
       "      <td>c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The generation of random, binary, unordered t...</td>\n",
       "      <td>m1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The intersection graph of paths in trees</td>\n",
       "      <td>m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graph minors IV: Widths of trees and well-qua...</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Graph minors: A survey</td>\n",
       "      <td>m4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content index\n",
       "0   Human machine interface for Lab ABC computer ...    c1\n",
       "1   A survey of user opinion of computer system r...    c2\n",
       "2           The EPS user interface management system    c3\n",
       "3   System and human system engineering testing o...    c4\n",
       "4   Relation of user-perceived response time to e...    c5\n",
       "5   The generation of random, binary, unordered t...    m1\n",
       "6           The intersection graph of paths in trees    m2\n",
       "7   Graph minors IV: Widths of trees and well-qua...    m3\n",
       "8                             Graph minors: A survey    m4"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = pd.DataFrame(columns = ['content'])\n",
    "\n",
    "titles = pd.DataFrame({'content':[\"c1: Human machine interface for Lab ABC computer applications\",\n",
    "                                  \"c2: A survey of user opinion of computer system response time\",\n",
    "                                  \"c3: The EPS user interface management system\",\n",
    "                                  \"c4: System and human system engineering testing of EPS\",\n",
    "                                  \"c5: Relation of user-perceived response time to error measurement\",\n",
    "                                  \"m1: The generation of random, binary, unordered trees\",\n",
    "                                  \"m2: The intersection graph of paths in trees\",\n",
    "                                  \"m3: Graph minors IV: Widths of trees and well-quasi-ordering\",\n",
    "                                  \"m4: Graph minors: A survey\"\n",
    "                                 ]})\n",
    "\n",
    "def getIndex(text):\n",
    "    return text.split(\":\")[0]\n",
    "\n",
    "def getContent(text):\n",
    "    return text[text.index(\":\")+1:]\n",
    "\n",
    "titles['index'] = titles['content'].apply(getIndex)\n",
    "titles['content'] = titles['content'].apply(getContent)\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "import re\n",
    "# import spacy\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "# nltk.set_proxy('http://10.144.1.10:8080')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def default_clean(text):\n",
    "    '''\n",
    "    Removes default bad characters\n",
    "    '''\n",
    "    if not (pd.isnull(text)):\n",
    "    # text = filter(lambda x: x in string.printable, text)\n",
    "        bad_chars = set([\"@\", '-', '|', '<', '>', \"+\", '/', \"'\", '\"', '\\\\','(',')', '\\\\n', '?', '#', ',','.', '[',']', '%', '$', '&', ';', '!', ';', ':',\"*\", \"_\", \"=\", \"}\", \"{\"])\n",
    "        for char in bad_chars:\n",
    "            text = text.replace(char, \" \")\n",
    "        text = re.sub('\\d+', \"\", text)\n",
    "#         print (text)\n",
    "    return text\n",
    " \n",
    "def stop_and_stem(text, stem=True, stemmer = PorterStemmer()):\n",
    "    '''\n",
    "    Removes stopwords and does stemming\n",
    "    '''\n",
    "#     print (text)\n",
    "    stoplist = stopwords.words('english')\n",
    "    if stem:\n",
    "        text_stemmed = [stemmer.stem(word.lower()) for word in word_tokenize(text) if word.lower() not in stoplist]\n",
    "    else:\n",
    "        text_stemmed = [word.lower() for word in word_tokenize(text) if word.lower() not in stoplist]\n",
    "    text = ' '.join(text_stemmed)\n",
    "#     print (text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles['tmp'] = titles['content'].apply(default_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles['tmp'] = titles['tmp'].apply(stop_and_stem, stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content index  \\\n",
      "0   Human machine interface for Lab ABC computer ...    c1   \n",
      "1   A survey of user opinion of computer system r...    c2   \n",
      "2           The EPS user interface management system    c3   \n",
      "3   System and human system engineering testing o...    c4   \n",
      "4   Relation of user-perceived response time to e...    c5   \n",
      "5   The generation of random, binary, unordered t...    m1   \n",
      "6           The intersection graph of paths in trees    m2   \n",
      "7   Graph minors IV: Widths of trees and well-qua...    m3   \n",
      "8                             Graph minors: A survey    m4   \n",
      "\n",
      "                                                 tmp  \n",
      "0  human machine interface lab abc computer appli...  \n",
      "1  survey user opinion computer system response time  \n",
      "2               eps user interface management system  \n",
      "3        system human system engineering testing eps  \n",
      "4  relation user perceived response time error me...  \n",
      "5           generation random binary unordered trees  \n",
      "6                     intersection graph paths trees  \n",
      "7   graph minors iv widths trees well quasi ordering  \n",
      "8                                graph minors survey  \n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stem'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词干化 ignore\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "st.stem('stemmed')     #=>'stem'\n",
    "st.stem('stemming')    #=>'stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分单词\n",
    "def tokenize(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (nltk.word_tokenize(sentence))\n",
    "data = list(titles['tmp'])        \n",
    "sentences = list(tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 0],\n",
       "       [0, 1, 1, 1]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.csr import csr_matrix\n",
    " \n",
    "docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
    "# docs = sentences\n",
    "indptr = [0]        # 存放的是行偏移量\n",
    "indices = []        # 存放的是data中元素对应的列编号（列编号可重复）\n",
    "data = []           # 存放的是非0数据元素\n",
    "vocabulary = {}     # key是word词汇，value是列编号\n",
    "for d in docs:      # 遍历每个文档\n",
    "    for term in d:  # 遍历文档的每个词汇term\n",
    "        # setdefault如果term不存在，则将新term和他的列\n",
    "        # 编号len(vocabulary)加入到词典中，返回他的编号；\n",
    "        # 如果term存在，则不填加，返回已存在的编号\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "# csr_matrix可以将同一个词汇次数求和\n",
    "csr_matrix((data, indices, indptr), dtype=int).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 0, 'world': 1, 'goodbye': 2, 'cruel': 3}\n",
      "[0, 3, 6]\n",
      "[0, 1, 0, 2, 3, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print (vocabulary)\n",
    "print(indptr)\n",
    "print(indices)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造词汇-文档矩阵 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from numpy import zeros\n",
    "from scipy.linalg import svd\n",
    "from math import log    # needed for TFIDF\n",
    "from numpy import asarray, sum\n",
    "\n",
    "\n",
    "class LSA(object):\n",
    "    def __init__(self):\n",
    "        self.wdict = {}\n",
    "        self.dcount = 0\n",
    "\n",
    "    def parse(self, docs):\n",
    "        for d in docs:\n",
    "            for w in d:\n",
    "                self.wdict.setdefault(w,[]).append(self.dcount)\n",
    "#                 if w in self.wdict:\n",
    "#                     self.wdict[w].append(self.dcount)\n",
    "#                 else:\n",
    "#                     self.wdict[w] = [self.dcount]\n",
    "            self.dcount += 1\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        # rows -> keywords (occur more than twice), cols -> documentID\n",
    "        # self.keys = [k for k in self.wdict.keys() if len(self.wdict[k]) > 1]\n",
    "        self.keys = [k for k in self.wdict.keys()]\n",
    "        self.keys.sort()\n",
    "        self.A = zeros([len(self.keys), self.dcount])\n",
    "        for i, k in enumerate(self.keys):\n",
    "            for d in self.wdict[k]:\n",
    "                self.A[i,d] += 1\n",
    "    \n",
    "    def calc(self):\n",
    "        #u大小为(M,M)，s大小为(M,N)，v大小为(N,N)\n",
    "        #sigma为了节约空间，只返回对角线非0值\n",
    "        self.U, self.S, self.Vt = svd(self.A)\n",
    "    \n",
    "    def TFIDF(self):\n",
    "        WordsPerDoc = sum(self.A, axis=0)\n",
    "        print(\"words\")\n",
    "        print(WordsPerDoc)\n",
    "        DocsPerWord = sum(asarray(self.A > 0, 'i'), axis=1)\n",
    "        print(\"docs\")\n",
    "        print(DocsPerWord)\n",
    "        rows, cols = self.A.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                self.A[i,j] = (self.A[i,j] / WordsPerDoc[j]) * log(float(cols) / (DocsPerWord[i]+1))\n",
    "    \n",
    "    def printA(self):\n",
    "        print ('Here is the count matrix')\n",
    "        print (self.A)\n",
    "    \n",
    "    def printSVD(self):\n",
    "        print ('Here are the singular values')\n",
    "        print (self.S)\n",
    "        print ('Here are the first 3 columns of the U matrix')\n",
    "        print (-1*self.U[:, 0:3])\n",
    "        print ('Here are the first 3 rows of the Vt matrix')\n",
    "        print (-1*self.Vt[0:3, :])\n",
    "\n",
    "#A=U*S*Vt\n",
    "#A 词*文档\n",
    "#U 词*语义\n",
    "#S 语义*主题\n",
    "#Vt 主题*文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n",
      "{'human': [0, 3], 'machine': [0], 'interface': [0, 2], 'lab': [0], 'abc': [0], 'computer': [0, 1], 'applications': [0], 'survey': [1, 8], 'user': [1, 2, 4], 'opinion': [1], 'system': [1, 2, 3, 3], 'response': [1, 4], 'time': [1, 4], 'eps': [2, 3], 'management': [2], 'engineering': [3], 'testing': [3], 'relation': [4], 'perceived': [4], 'error': [4], 'measurement': [4], 'generation': [5], 'random': [5], 'binary': [5], 'unordered': [5], 'trees': [5, 6, 7], 'intersection': [6], 'graph': [6, 7, 8], 'paths': [6], 'minors': [7, 8], 'iv': [7], 'widths': [7], 'well': [7], 'quasi': [7], 'ordering': [7]}\n",
      "9\n",
      "['abc', 'applications', 'binary', 'computer', 'engineering', 'eps', 'error', 'generation', 'graph', 'human', 'interface', 'intersection', 'iv', 'lab', 'machine', 'management', 'measurement', 'minors', 'opinion', 'ordering', 'paths', 'perceived', 'quasi', 'random', 'relation', 'response', 'survey', 'system', 'testing', 'time', 'trees', 'unordered', 'user', 'well', 'widths']\n",
      "Here is the count matrix\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "words\n",
      "[7. 7. 5. 6. 7. 5. 4. 8. 3.]\n",
      "docs\n",
      "[1 1 1 2 1 2 1 1 3 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 3 1 2 3 1 3 1 1]\n",
      "Here is the count matrix\n",
      "[[0.2148682  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.2148682  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.30081548\n",
      "  0.         0.         0.        ]\n",
      " [0.15694461 0.15694461 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.25067957 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.21972246 0.18310205 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2148682  0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.30081548\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.20273255 0.10136628 0.27031007]\n",
      " [0.15694461 0.         0.         0.18310205 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.15694461 0.         0.21972246 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37601935 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18800967 0.        ]\n",
      " [0.2148682  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.2148682  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.30081548 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2148682  0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13732654 0.3662041 ]\n",
      " [0.         0.2148682  0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18800967 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37601935 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2148682  0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18800967 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.30081548\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2148682  0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.15694461 0.         0.         0.15694461 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.15694461 0.         0.         0.         0.\n",
      "  0.         0.         0.3662041 ]\n",
      " [0.         0.11584717 0.16218604 0.27031007 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.25067957 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.15694461 0.         0.         0.15694461 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.16218604\n",
      "  0.20273255 0.10136628 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.30081548\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.11584717 0.16218604 0.         0.11584717 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18800967 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18800967 0.        ]]\n",
      "Here are the singular values\n",
      "[0.67597555 0.62425526 0.61096102 0.5539611  0.51722333 0.48935126\n",
      " 0.42746009 0.4055805  0.33556226]\n",
      "Here are the first 3 columns of the U matrix\n",
      "[[ 0.01116307 -0.07028783  0.10851752]\n",
      " [ 0.01116307 -0.07028783  0.10851752]\n",
      " [ 0.16690453  0.34918978  0.25106661]\n",
      " [ 0.04153069 -0.11720297  0.12665904]\n",
      " [ 0.01968175 -0.13172347  0.20766564]\n",
      " [ 0.03229073 -0.20744452  0.32172179]\n",
      " [ 0.01523728 -0.05406866  0.05711441]\n",
      " [ 0.16690453  0.34918978  0.25106661]\n",
      " [ 0.46752049 -0.14140807 -0.18626504]\n",
      " [ 0.02252975 -0.14755364  0.23094736]\n",
      " [ 0.02606849 -0.16257053  0.24930175]\n",
      " [ 0.34686252  0.04071178 -0.10786586]\n",
      " [ 0.08891418 -0.02172174 -0.03521633]\n",
      " [ 0.01116307 -0.07028783  0.10851752]\n",
      " [ 0.01116307 -0.07028783  0.10851752]\n",
      " [ 0.02452653 -0.15228264  0.23279409]\n",
      " [ 0.01523728 -0.05406866  0.05711441]\n",
      " [ 0.38001976 -0.22131019 -0.17355594]\n",
      " [ 0.04569536 -0.09017127  0.06488761]\n",
      " [ 0.08891418 -0.02172174 -0.03521633]\n",
      " [ 0.34686252  0.04071178 -0.10786586]\n",
      " [ 0.01523728 -0.05406866  0.05711441]\n",
      " [ 0.08891418 -0.02172174 -0.03521633]\n",
      " [ 0.16690453  0.34918978  0.25106661]\n",
      " [ 0.01523728 -0.05406866  0.05711441]\n",
      " [ 0.04450659 -0.10535612  0.08911305]\n",
      " [ 0.34845175 -0.27130728 -0.10043775]\n",
      " [ 0.05908346 -0.27275876  0.38442421]\n",
      " [ 0.01968175 -0.13172347  0.20766564]\n",
      " [ 0.04450659 -0.10535612  0.08911305]\n",
      " [ 0.32493835  0.19850583  0.05822029]\n",
      " [ 0.16690453  0.34918978  0.25106661]\n",
      " [ 0.0460757  -0.15987151  0.19128995]\n",
      " [ 0.08891418 -0.02172174 -0.03521633]\n",
      " [ 0.08891418 -0.02172174 -0.03521633]]\n",
      "Here are the first 3 rows of the Vt matrix\n",
      "[[ 0.03511903  0.14375764  0.05511462  0.05307325  0.04793651  0.37505843\n",
      "   0.6235599   0.31968469  0.5815961 ]\n",
      " [-0.2042068  -0.26197404 -0.31601845 -0.32802462 -0.15708535  0.72464208\n",
      "   0.06758839 -0.07212348 -0.3502134 ]\n",
      " [ 0.30856113  0.18450286  0.47280851  0.50612665  0.16240039  0.50992027\n",
      "  -0.17526182 -0.11443989 -0.24663919]]\n",
      "A  (35, 9)\n",
      "U  (35, 35)\n",
      "S  (9,)\n",
      "Vt  (9, 9)\n"
     ]
    }
   ],
   "source": [
    "mylsa =  LSA()\n",
    "\n",
    "print(sentences)\n",
    "mylsa.parse(sentences)\n",
    "print(mylsa.wdict)\n",
    "print(mylsa.dcount)\n",
    "mylsa.build()\n",
    "print(mylsa.keys)\n",
    "mylsa.printA()\n",
    "mylsa.TFIDF()\n",
    "mylsa.printA()\n",
    "mylsa.calc()\n",
    "mylsa.printSVD()\n",
    "print(\"A \", mylsa.A.shape)\n",
    "print(\"U \", mylsa.U.shape)\n",
    "print(\"S \", mylsa.S.shape)\n",
    "print(\"Vt \", mylsa.Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[0.67597555 0.62425526 0.61096102 0.5539611  0.51722333 0.48935126\n",
      " 0.42746009 0.4055805  0.33556226]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mylsa.S.shape[0])\n",
    "#选取 K， 使得特征值保留 > 90%\n",
    "def selectK(S):\n",
    "    maxNum=S.shape[0]\n",
    "    totalValue=sum(S)\n",
    "    print(S)\n",
    "    for k in range(1,maxNum+1):\n",
    "        if(sum(S[0:k])/totalValue > 0.9):\n",
    "            return k\n",
    "\n",
    "K = selectK(mylsa.S)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 35)\n",
      "(35, 8)\n"
     ]
    }
   ],
   "source": [
    "print(mylsa.U.shape)\n",
    "Ureduce = mylsa.U[:,0:K]\n",
    "print(Ureduce.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印所有word-潜在的K个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'applications', 'binary', 'computer', 'engineering', 'eps', 'error', 'generation', 'graph', 'human', 'interface', 'intersection', 'iv', 'lab', 'machine', 'management', 'measurement', 'minors', 'opinion', 'ordering', 'paths', 'perceived', 'quasi', 'random', 'relation', 'response', 'survey', 'system', 'testing', 'time', 'trees', 'unordered', 'user', 'well', 'widths']\n",
      "          latent0   latent1   latent2   latent3   latent4   latent5   latent6   latent7   \n",
      "abc       -0.0111   0.07028   -0.1085   0.03915   -0.0810   0.39132   0.02012   -0.0475   \n",
      "applica   -0.0111   0.07028   -0.1085   0.03915   -0.0810   0.39132   0.02012   -0.0475   \n",
      "binary    -0.1669   -0.3491   -0.2510   -0.1436   -0.0170   -0.0003   -0.0393   0.00263   \n",
      "compute   -0.0415   0.11720   -0.1266   -0.0261   0.02752   0.30325   -0.0683   -0.0470   \n",
      "enginee   -0.0196   0.13172   -0.2076   0.08283   -0.1220   -0.2045   -0.0112   -0.3745   \n",
      "eps       -0.0322   0.20744   -0.3217   0.11085   -0.1082   -0.2391   0.03780   0.14507   \n",
      "error     -0.0152   0.05406   -0.0571   -0.0634   0.35164   0.01943   0.09723   -0.0800   \n",
      "generat   -0.1669   -0.3491   -0.2510   -0.1436   -0.0170   -0.0003   -0.0393   0.00263   \n",
      "graph     -0.4675   0.14140   0.18626   -0.0058   -0.0601   -0.0086   -0.0365   0.00933   \n",
      "human     -0.0225   0.14755   -0.2309   0.08910   -0.1483   0.13643   0.00651   -0.3083   \n",
      "interfa   -0.0260   0.16257   -0.2493   0.07894   -0.0782   0.19612   0.06069   0.38391   \n",
      "interse   -0.3468   -0.0407   0.10786   0.49472   0.13530   0.01344   -0.0823   0.00085   \n",
      "iv        -0.0889   0.02172   0.03521   -0.0503   -0.0569   -0.0111   0.39016   -0.0232   \n",
      "lab       -0.0111   0.07028   -0.1085   0.03915   -0.0810   0.39132   0.02012   -0.0475   \n",
      "machine   -0.0111   0.07028   -0.1085   0.03915   -0.0810   0.39132   0.02012   -0.0475   \n",
      "managem   -0.0245   0.15228   -0.2327   0.06893   -0.0261   -0.1228   0.06296   0.57319   \n",
      "measure   -0.0152   0.05406   -0.0571   -0.0634   0.35164   0.01943   0.09723   -0.0800   \n",
      "minors    -0.3800   0.22131   0.17355   -0.3692   -0.1802   -0.0215   0.01061   0.01201   \n",
      "opinion   -0.0456   0.09017   -0.0648   -0.0749   0.11870   0.02384   -0.1137   -0.0168   \n",
      "orderin   -0.0889   0.02172   0.03521   -0.0503   -0.0569   -0.0111   0.39016   -0.0232   \n",
      "paths     -0.3468   -0.0407   0.10786   0.49472   0.13530   0.01344   -0.0823   0.00085   \n",
      "perceiv   -0.0152   0.05406   -0.0571   -0.0634   0.35164   0.01943   0.09723   -0.0800   \n",
      "quasi     -0.0889   0.02172   0.03521   -0.0503   -0.0569   -0.0111   0.39016   -0.0232   \n",
      "random    -0.1669   -0.3491   -0.2510   -0.1436   -0.0170   -0.0003   -0.0393   0.00263   \n",
      "relatio   -0.0152   0.05406   -0.0571   -0.0634   0.35164   0.01943   0.09723   -0.0800   \n",
      "respons   -0.0445   0.10535   -0.0891   -0.1011   0.34354   0.03161   -0.0120   -0.0708   \n",
      "survey    -0.3484   0.27130   0.10043   -0.3872   -0.0519   0.00405   -0.3574   0.01668   \n",
      "system    -0.0590   0.27275   -0.3844   0.08605   -0.0816   -0.2739   -0.0394   -0.1039   \n",
      "testing   -0.0196   0.13172   -0.2076   0.08283   -0.1220   -0.2045   -0.0112   -0.3745   \n",
      "time      -0.0445   0.10535   -0.0891   -0.1011   0.34354   0.03161   -0.0120   -0.0708   \n",
      "trees     -0.3249   -0.1985   -0.0582   0.16215   0.03303   0.00100   0.14470   -0.0106   \n",
      "unorder   -0.1669   -0.3491   -0.2510   -0.1436   -0.0170   -0.0003   -0.0393   0.00263   \n",
      "user      -0.0460   0.15987   -0.1912   -0.0374   0.23950   -0.0428   0.02504   0.25676   \n",
      "well      -0.0889   0.02172   0.03521   -0.0503   -0.0569   -0.0111   0.39016   -0.0232   \n",
      "widths    -0.0889   0.02172   0.03521   -0.0503   -0.0569   -0.0111   0.39016   -0.0232   \n"
     ]
    }
   ],
   "source": [
    "print(mylsa.keys)\n",
    "\n",
    "def printRow(text):\n",
    "     print('%-10.7s' % text, end=\"\")\n",
    "#      print('%.1f' % text, end=\"    \")\n",
    "    \n",
    "printRow(\"\")\n",
    "for i in range(Ureduce.shape[1]):\n",
    "    printRow(f'latent{i}')\n",
    "print()\n",
    "\n",
    "for row in range(Ureduce.shape[0]):\n",
    "    printRow(mylsa.keys[row])\n",
    "    for col in range(Ureduce.shape[1]):\n",
    "        printRow(Ureduce[row,col])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 打印所有文章 在K维（基于隐义topic）D_kxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          c1        c2        c3        c4        c5        m1        m2        m3        m4        \n",
      "topic0    -0.0351   -0.1437   -0.0551   -0.0530   -0.0479   -0.3750   -0.6235   -0.3196   -0.5815   \n",
      "topic1    0.20420   0.26197   0.31601   0.32802   0.15708   -0.7246   -0.0675   0.07212   0.35021   \n",
      "topic2    -0.3085   -0.1845   -0.4728   -0.5061   -0.1624   -0.5099   0.17526   0.11443   0.24663   \n",
      "topic3    0.10093   -0.1933   0.12694   0.18306   -0.1635   -0.2644   0.72883   -0.1483   -0.5028   \n",
      "topic4    -0.1950   0.28573   -0.0449   -0.2517   0.84645   -0.0293   0.18611   -0.1567   -0.1958   \n",
      "topic5    0.89122   0.05431   -0.1997   -0.3992   0.04425   -0.0006   0.01750   -0.0291   -0.0178   \n",
      "topic6    0.04004   -0.2262   0.08947   -0.0191   0.19343   -0.0559   -0.0936   0.88708   -0.3202   \n",
      "topic7    -0.0898   -0.0318   0.77281   -0.6060   -0.1511   0.00355   0.00092   -0.0502   0.03213   \n"
     ]
    }
   ],
   "source": [
    "D_kxd = mylsa.Vt[:K,:]\n",
    "\n",
    "printRow(\"\")\n",
    "for i in range(titles['index'].size):\n",
    "    printRow(titles['index'][i])\n",
    "print()\n",
    "\n",
    "for row in range(K):\n",
    "    printRow(f'topic{row}')\n",
    "    for col in range(D_kxd.shape[1]):\n",
    "        printRow(D_kxd[row,col])\n",
    "    print()\n",
    "#后面查询就跟 D_kxd进行相似度计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['system', 'user']\n",
      "Dq = [[-0.15556651  0.69303423 -0.94230915  0.08771285  0.30516352 -0.64736982\n",
      "  -0.03370896  0.37675818]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#根据输入 构造1*topic 的 Dq = 1*K = Xq(1*wordnum) *  Ureduce（wordnum*k） *  S-1（K*K 的逆矩阵）\n",
    "query=\"a system, user\"\n",
    "Xq = zeros([1, len(mylsa.keys)])\n",
    "\n",
    "text=default_clean(query)\n",
    "text=stop_and_stem(text, False)\n",
    "qwords = nltk.word_tokenize(text)\n",
    "print(qwords)\n",
    "\n",
    "for i in range(len(mylsa.keys)):\n",
    "    Xq[0,i] += qwords.count(mylsa.keys[i])\n",
    "\n",
    "# print(Dq.transpose())\n",
    "#  np.linalg.inv\n",
    "\n",
    "# S=mylsa.S[0:K]\n",
    "# print(S)\n",
    "\n",
    "# rebuild Sigma\n",
    "S=zeros([K, K]);\n",
    "for i in range(K):\n",
    "    S[i, i]=mylsa.S[i]\n",
    "\n",
    "Dq = np.dot(np.dot(Xq, Ureduce), np.linalg.inv(S))\n",
    "\n",
    "print(f'Dq = {Dq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15774672  0.52233922  0.76282757  0.47834595  0.31702675  0.0056792\n",
      " -0.00145672 -0.07051911  0.02284328]\n"
     ]
    }
   ],
   "source": [
    "nums=cosine_similarity(Dq, D_kxd)\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your search: a system, user\n",
      "c3         The EPS user interface management system\n",
      "c2         A survey of user opinion of computer system response time\n",
      "c4         System and human system engineering testing of EPS\n"
     ]
    }
   ],
   "source": [
    "highIndexs = nums.argsort()[-3:][::-1]\n",
    "\n",
    "print(\"your search: \" + query)\n",
    "\n",
    "# print(highIndexs)\n",
    "for i in highIndexs:\n",
    "    printRow(titles[\"index\"][i])\n",
    "    print(titles[\"content\"][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
